{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.models\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "from gensim import utils\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "\n",
    "\n",
    "\n",
    "import pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# txt_test_sample.txt\n",
    "\n",
    "with open('Original_Forums.txt', mode='r', encoding='iso-8859-1') as f:\n",
    "    \n",
    "    # find CarType, MsgTitle, MsgAuther, MsgDate and Msg in file\n",
    "    car_type = []    # car tyepe: Makt + model\n",
    "    makes = []\n",
    "    msg_date = []\n",
    "    msg_title = []\n",
    "    msg_author = []\n",
    "    reviews = [] \n",
    "        \n",
    "    while True:\n",
    "            \n",
    "        end_of_message = False  # message end flag init\n",
    "        \n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "            \n",
    "        if len(line) == 1:\n",
    "            # message session end when read blank line\n",
    "            end_of_message = True\n",
    "            \n",
    "        if end_of_message:\n",
    "            # when the message sessin end, append to review list\n",
    "            reviews.append(msg)\n",
    "            \n",
    "        if line.startswith('CarType:'):\n",
    "            # get car type line\n",
    "            type_ = line.split(':')[-1]\n",
    "            car_type.append(type_)\n",
    "            try:\n",
    "                makes.append(type_.split()[1])\n",
    "            except IndexError:\n",
    "                # error happened on '71-Mazda6'\n",
    "                makes.append(type_.split('-')[1].replace('6', ''))\n",
    "            msg = ''    # init msg      \n",
    "        elif line.startswith('MsgTitle:'):\n",
    "            msg_title.append(line.split(':')[-1])\n",
    "        elif line.startswith('MsgAuther:'):\n",
    "            msg_author.append(line.split(':')[-1])\n",
    "        elif line.startswith('MsgDate:'):\n",
    "            time = line.split('Date:')[-1]\n",
    "            msg_date.append(time)  \n",
    "        elif line.startswith(' ') and not end_of_message:\n",
    "            msg += line\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df['make'] = makes\n",
    "    df['type'] = car_type\n",
    "    df['title'] = msg_title\n",
    "    df['author'] = msg_author\n",
    "    df['date'] = msg_date\n",
    "    df['review'] = reviews\n",
    "\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    # rm '\\n' in cells\n",
    "    df[df.columns[i]] = df[df.columns[i]].apply(lambda x: str(x).replace('\\n', ''))\n",
    "    \n",
    "# df.to_csv('original_review.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Acura', 'Audi', 'BMW', 'Buick', 'Cadillac', 'Chevrolet',\n",
       "       'Chrysler', 'Dodge', 'Dodge/Plymouth', 'Ford', 'Honda', 'Hyundai',\n",
       "       'Infiniti', 'Jaguar', 'Kia', 'Lexus', 'Lincoln', 'Maserati',\n",
       "       'Mazda', 'Mercedes-Benz', 'Mercedes', 'Mitsubishi', 'Nissan',\n",
       "       'Oldsmobile', 'Pontiac', 'Saab', 'Saturn', 'Suzuki', 'Toyota',\n",
       "       'Volkswagen', 'Volvo'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df['make'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Honda', 'Toyota', 'Nissan', 'Lexus', 'BMW', 'Audi', 'Acura']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 brands for compare, and each brands saved as individual .csv\n",
    "makes = 'Honda Toyota Nissan Lexus BMW Audi Acura'.split()\n",
    "makes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 7 brands now, 4 luxury and 4 general.\n",
    "\n",
    "Luxury | General\n",
    ":-: | :-:\n",
    "Acura | Honda\n",
    "BMW | Nissan\n",
    "Lexus | Toyota\n",
    "Audi| \n",
    "\n",
    "They also have some hidden relations, like Acura is a child company of Honda, and Lexus belong to Toyota, these related brands may have some unusual score than those just in same level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in makes:\n",
    "    temp = df[df['make'] == i]\n",
    "    temp = temp.dropna(axis=0)\n",
    "    temp.reset_index(inplace=True, drop=True)\n",
    "    temp.to_csv('data/{}.csv'.format(i), index=None)\n",
    "\n",
    "        \n",
    "merged = pd.read_csv('data/csv_data/Honda.csv')\n",
    "merged = merged.append(pd.read_csv('data/csv_data/Acura.csv'))\n",
    "merged = merged.append(pd.read_csv('data/csv_data/Toyota.csv'))\n",
    "merged = merged.append(pd.read_csv('data/csv_data/Nissan.csv'))\n",
    "merged = merged.append(pd.read_csv('data/csv_data/Lexus.csv'))\n",
    "merged = merged.append(pd.read_csv('data/csv_data/BMW.csv'))\n",
    "merged = merged.append(pd.read_csv('data/csv_data/Audi.csv'))\n",
    "merged.reset_index(inplace=True, drop=True)\n",
    "merged.to_csv('data/merged7.csv', index=None)\n",
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>45-Honda Honda Accord</td>\n",
       "      <td>I Don't Understand [dtownfb]</td>\n",
       "      <td>hondacrv1</td>\n",
       "      <td>Jan 23, 2007 (11:50 am)</td>\n",
       "      <td>Thanks!  Also i forgot to say that since i wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Honda</td>\n",
       "      <td>45-Honda Honda Accord</td>\n",
       "      <td>Does Hawaii Honda Dealers honor internet EW?</td>\n",
       "      <td>hicrvguy</td>\n",
       "      <td>Jan 24, 2007 (2:34 pm)</td>\n",
       "      <td>Thank God for the internet!  First of all, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>45-Honda Honda Accord</td>\n",
       "      <td>Does Hawaii Honda Dealers honor internet EW? ...</td>\n",
       "      <td>dwynne</td>\n",
       "      <td>Jan 24, 2007 (3:11 pm)</td>\n",
       "      <td>I am pretty sure than once you are past the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda</td>\n",
       "      <td>45-Honda Honda Accord</td>\n",
       "      <td>Does Hawaii Honda Dealers honor internet EW? ...</td>\n",
       "      <td>hicrvguy</td>\n",
       "      <td>Jan 24, 2007 (4:00 pm)</td>\n",
       "      <td>Really?  Geez I just got a quote for the Hond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honda</td>\n",
       "      <td>45-Honda Honda Accord</td>\n",
       "      <td>Does Hawaii Honda Dealers honor internet EW? ...</td>\n",
       "      <td>skap2</td>\n",
       "      <td>Jan 24, 2007 (6:41 pm)</td>\n",
       "      <td>I am still deciding on Honda HondaCare for ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401531</th>\n",
       "      <td>Audi</td>\n",
       "      <td>8-Audi Audi S4</td>\n",
       "      <td>M3 v S4</td>\n",
       "      <td>diver110</td>\n",
       "      <td>Mar 13, 2004 (5:34 am)</td>\n",
       "      <td>FWIW, I have tested 2004s of both and (everyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401532</th>\n",
       "      <td>Audi</td>\n",
       "      <td>8-Audi Audi S4</td>\n",
       "      <td>Diver110 -</td>\n",
       "      <td>kevin111</td>\n",
       "      <td>Mar 13, 2004 (8:52 pm)</td>\n",
       "      <td>Does the S4 need special Oil, when giving it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401533</th>\n",
       "      <td>Audi</td>\n",
       "      <td>8-Audi Audi S4</td>\n",
       "      <td>1997 M3, Check Engine Light</td>\n",
       "      <td>97bimmerm3</td>\n",
       "      <td>Mar 24, 2004 (6:29 am)</td>\n",
       "      <td>I recently purchased a 1997 M3 with 72K miles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401534</th>\n",
       "      <td>Audi</td>\n",
       "      <td>8-Audi Audi S4</td>\n",
       "      <td>Want to know positives/negatives of S4 and M3</td>\n",
       "      <td>jlmagicarethus</td>\n",
       "      <td>Feb 05, 2004 (10:24 pm)</td>\n",
       "      <td>I'm looking into getting either a S4 or M3 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401535</th>\n",
       "      <td>Audi</td>\n",
       "      <td>8-Audi Audi S4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>jlmagicarethus, it would help if you would as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401536 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         make                    type  \\\n",
       "0       Honda   45-Honda Honda Accord   \n",
       "1       Honda   45-Honda Honda Accord   \n",
       "2       Honda   45-Honda Honda Accord   \n",
       "3       Honda   45-Honda Honda Accord   \n",
       "4       Honda   45-Honda Honda Accord   \n",
       "...       ...                     ...   \n",
       "401531   Audi          8-Audi Audi S4   \n",
       "401532   Audi          8-Audi Audi S4   \n",
       "401533   Audi          8-Audi Audi S4   \n",
       "401534   Audi          8-Audi Audi S4   \n",
       "401535   Audi          8-Audi Audi S4   \n",
       "\n",
       "                                                    title           author  \\\n",
       "0                            I Don't Understand [dtownfb]        hondacrv1   \n",
       "1            Does Hawaii Honda Dealers honor internet EW?         hicrvguy   \n",
       "2        Does Hawaii Honda Dealers honor internet EW? ...           dwynne   \n",
       "3        Does Hawaii Honda Dealers honor internet EW? ...         hicrvguy   \n",
       "4        Does Hawaii Honda Dealers honor internet EW? ...            skap2   \n",
       "...                                                   ...              ...   \n",
       "401531                                            M3 v S4         diver110   \n",
       "401532                                         Diver110 -         kevin111   \n",
       "401533                        1997 M3, Check Engine Light       97bimmerm3   \n",
       "401534      Want to know positives/negatives of S4 and M3   jlmagicarethus   \n",
       "401535                                                                       \n",
       "\n",
       "                            date  \\\n",
       "0        Jan 23, 2007 (11:50 am)   \n",
       "1         Jan 24, 2007 (2:34 pm)   \n",
       "2         Jan 24, 2007 (3:11 pm)   \n",
       "3         Jan 24, 2007 (4:00 pm)   \n",
       "4         Jan 24, 2007 (6:41 pm)   \n",
       "...                          ...   \n",
       "401531    Mar 13, 2004 (5:34 am)   \n",
       "401532    Mar 13, 2004 (8:52 pm)   \n",
       "401533    Mar 24, 2004 (6:29 am)   \n",
       "401534   Feb 05, 2004 (10:24 pm)   \n",
       "401535                             \n",
       "\n",
       "                                                   review  \n",
       "0        Thanks!  Also i forgot to say that since i wa...  \n",
       "1        Thank God for the internet!  First of all, al...  \n",
       "2        I am pretty sure than once you are past the f...  \n",
       "3        Really?  Geez I just got a quote for the Hond...  \n",
       "4        I am still deciding on Honda HondaCare for ne...  \n",
       "...                                                   ...  \n",
       "401531   FWIW, I have tested 2004s of both and (everyt...  \n",
       "401532   Does the S4 need special Oil, when giving it ...  \n",
       "401533   I recently purchased a 1997 M3 with 72K miles...  \n",
       "401534   I'm looking into getting either a S4 or M3 of...  \n",
       "401535   jlmagicarethus, it would help if you would as...  \n",
       "\n",
       "[401536 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('data/csv_data/merged7.csv')\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we gonna figure out the total appearence of each brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Honda': 92130, 'Toyota': 55362, 'Nissan': 31877, 'Lexus': 55192, 'BMW': 88721, 'Audi': 31438, 'Acura': 46816}\n"
     ]
    }
   ],
   "source": [
    "# merged = pd.read_csv('data/merged6.csv')\n",
    " \n",
    "num_review = {}  # count the num of brands reviews\n",
    "for i in makes:\n",
    "    temp = pd.read_csv('data/csv_data/{}.csv'.format(i))\n",
    "    num_review['{}'.format(i)] = temp.shape[0]\n",
    "print(num_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$LIFT = \\frac{P(A*B)}{P(A)*P(B)}$$\n",
    "P(A*B) means the count of A and B co-mentioned.<br>\n",
    "P(A) and P(B) means count of A or B in reviews \n",
    "\n",
    "reference paper: [Mine Your Own Business: Market Structure Surveillance through Text Mining.](http://www.columbia.edu/~on2110/Papers/Netzer_Feldman_Goldenberg_Fresko_2012.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This function is aiming to calculate the LIFT score when two brands showed together. Once find the target words showed in the,\n",
    "review simutaneously, counter plus 1, but no matter how many times it appear in one review, it will always counted as 1 time.\n",
    "Like, Toyota is similar to Honda, but Toyota is more porpular in Dallas, although Toyota appeared twice in this sentence, it will just\n",
    "count as 1 time.\n",
    "\n",
    "But the bigest problem is proplr not always called a car with its total name, like Honda civic, peoplr usually ignore the brand\n",
    "name, these data from a website highly related to cars, users might pretty fimilar with car information. So, those just mentioned \n",
    "certain make name, will not be counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Honda_BMW_lift', 1.274), ('Honda_Lexus_lift', 1.554), ('Honda_Audi_lift', 1.947), ('Honda_Nissan_lift', 4.331), ('Honda_Acura_lift', 4.605), ('Honda_Toyota_lift', 7.611)]\n",
      "\n",
      "\n",
      "[('Toyota_BMW_lift', 1.507), ('Toyota_Audi_lift', 1.85), ('Toyota_Acura_lift', 2.631), ('Toyota_Lexus_lift', 4.608), ('Toyota_Nissan_lift', 5.032), ('Toyota_Honda_lift', 7.56)]\n",
      "\n",
      "\n",
      "[('Nissan_BMW_lift', 2.365), ('Nissan_Lexus_lift', 2.796), ('Nissan_Audi_lift', 3.273), ('Nissan_Acura_lift', 3.967), ('Nissan_Honda_lift', 10.011), ('Nissan_Toyota_lift', 12.67)]\n",
      "\n",
      "\n",
      "[('Lexus_Honda_lift', 2.212), ('Lexus_Nissan_lift', 3.78), ('Lexus_Acura_lift', 8.41), ('Lexus_Toyota_lift', 9.913), ('Lexus_BMW_lift', 14.05), ('Lexus_Audi_lift', 14.201)]\n",
      "\n",
      "\n",
      "[('BMW_Honda_lift', 1.783), ('BMW_Toyota_lift', 2.244), ('BMW_Nissan_lift', 3.069), ('BMW_Acura_lift', 5.564), ('BMW_Lexus_lift', 7.593), ('BMW_Audi_lift', 13.201)]\n",
      "\n",
      "\n",
      "[('Audi_Honda_lift', 2.583), ('Audi_Toyota_lift', 3.947), ('Audi_Nissan_lift', 4.031), ('Audi_Acura_lift', 9.091), ('Audi_Lexus_lift', 12.063), ('Audi_BMW_lift', 15.718)]\n",
      "\n",
      "\n",
      "[('Acura_Toyota_lift', 3.704), ('Acura_Nissan_lift', 4.945), ('Acura_Honda_lift', 8.027), ('Acura_Lexus_lift', 11.189), ('Acura_BMW_lift', 13.131), ('Acura_Audi_lift', 17.115)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def bi_gram(makes):\n",
    "    for outer_make in makes:\n",
    "\n",
    "        frequency = {}   # count co-mentioned, empty dict \n",
    "        lift = {}        # lift score, empty dict\n",
    "        temp = pd.read_csv('data/csv_data/{}.csv'.format(outer_make))\n",
    "        num_review['{}'.format(outer_make)] = temp.shape[0]          # denominator\n",
    "\n",
    "        for inner_make in [make for make in makes if make != outer_make]:        \n",
    "            counter = 0   # counter for appearence\n",
    "            combined_name = '{}_{}'.format(outer_make, inner_make)\n",
    "            \n",
    "            for review in temp['review']:\n",
    "                if inner_make in str(review):\n",
    "                    counter += 1\n",
    "            frequency[combined_name] = counter      # co-mentioned, numerator\n",
    "            lift[combined_name+'_lift'] = \\\n",
    "                    round(frequency[combined_name] / \\\n",
    "                    (num_review[combined_name.split('_')[0]] * \\\n",
    "                    num_review[combined_name.split('_')[1]]) * (10**7), 3)     # scale by 10e7 and keep 3 digits\n",
    "\n",
    "        sorted_lift = sorted(lift.items(), key=operator.itemgetter(1))         # sort dict by value in increading\n",
    "\n",
    "        print(sorted_lift)\n",
    "        print('\\n')\n",
    "        \n",
    "bi_gram(makes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result showing above, we can clearly know that the relations between different brands. Like for Honda, it have a obvious high relation with Toyota, which is cater to the normal concept. And hidden relations also worked, Honda_Acura have a higher score than Honda_Nissan<br>\n",
    "\n",
    "dicsussion|switching\n",
    ":-:|:-:\n",
    "![dicsussion](img/discussion.png \"disscussion\")|![switching](img/switching.png \"switching\")\n",
    "                        <a id=\"Figure1\">Figure 1</a>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, tri-gram will be counted, and all other steps similar to the above bi-gram function. \n",
    "Function start at a brand, and then search in the reviews if two other brands sppeared in the review. However, the sequence of \n",
    "these two brand is doesn't matter, this cause a problem that some overlapping happened, Honda_Nissan_Toyota, and Honda_Toyota_Nissan\n",
    "is excately same result actually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Honda_Nissan_BMW_lift', 2.648), ('Honda_Lexus_Audi_lift', 2.878), ('Honda_Lexus_BMW_lift', 3.236), ('Honda_Nissan_Audi_lift', 3.358), ('Honda_Toyota_BMW_lift', 3.624), ('Honda_BMW_Acura_lift', 4.338), ('Honda_Nissan_Lexus_lift', 4.442), ('Honda_BMW_Audi_lift', 4.514), ('Honda_Toyota_Audi_lift', 4.74), ('Honda_Audi_Acura_lift', 5.752), ('Honda_Nissan_Acura_lift', 7.491), ('Honda_Lexus_Acura_lift', 8.696), ('Honda_Toyota_Lexus_lift', 9.165), ('Honda_Toyota_Acura_lift', 9.213), ('Honda_Toyota_Nissan_lift', 34.689)]\n",
      "\n",
      "\n",
      "[('Toyota_Nissan_BMW_lift', 3.321), ('Toyota_Lexus_Audi_lift', 3.331), ('Toyota_BMW_Acura_lift', 3.349), ('Toyota_Honda_BMW_lift', 3.602), ('Toyota_BMW_Audi_lift', 4.145), ('Toyota_Audi_Acura_lift', 4.295), ('Toyota_Nissan_Audi_lift', 4.506), ('Toyota_Honda_Audi_lift', 4.615), ('Toyota_Lexus_BMW_lift', 4.722), ('Toyota_Nissan_Acura_lift', 5.931), ('Toyota_Honda_Lexus_lift', 6.536), ('Toyota_Nissan_Lexus_lift', 8.111), ('Toyota_Lexus_Acura_lift', 11.115), ('Toyota_Honda_Acura_lift', 11.391), ('Toyota_Honda_Nissan_lift', 25.709)]\n",
      "\n",
      "\n",
      "[('Nissan_Honda_BMW_lift', 6.141), ('Nissan_Honda_Lexus_lift', 6.971), ('Nissan_Lexus_BMW_lift', 7.111), ('Nissan_Toyota_BMW_lift', 7.217), ('Nissan_BMW_Acura_lift', 7.628), ('Nissan_Honda_Audi_lift', 7.907), ('Nissan_Toyota_Audi_lift', 7.931), ('Nissan_Lexus_Audi_lift', 8.678), ('Nissan_Audi_Acura_lift', 8.739), ('Nissan_BMW_Audi_lift', 10.46), ('Nissan_Lexus_Acura_lift', 12.869), ('Nissan_Honda_Acura_lift', 13.601), ('Nissan_Toyota_Acura_lift', 14.524), ('Nissan_Toyota_Lexus_lift', 16.53), ('Nissan_Honda_Toyota_lift', 77.066)]\n",
      "\n",
      "\n",
      "[('Lexus_Honda_BMW_lift', 6.872), ('Lexus_Honda_Audi_lift', 8.633), ('Lexus_Honda_Nissan_lift', 10.303), ('Lexus_Honda_Toyota_lift', 13.215), ('Lexus_Nissan_BMW_lift', 13.39), ('Lexus_Honda_Acura_lift', 13.779), ('Lexus_Nissan_Audi_lift', 15.91), ('Lexus_Nissan_Acura_lift', 16.754), ('Lexus_Toyota_Acura_lift', 17.477), ('Lexus_Toyota_Audi_lift', 20.3), ('Lexus_Toyota_BMW_lift', 21.211), ('Lexus_Toyota_Nissan_lift', 24.024), ('Lexus_BMW_Acura_lift', 37.122), ('Lexus_Audi_Acura_lift', 56.997), ('Lexus_BMW_Audi_lift', 86.201)]\n",
      "\n",
      "\n",
      "[('BMW_Honda_Lexus_lift', 5.675), ('BMW_Honda_Audi_lift', 7.316), ('BMW_Toyota_Acura_lift', 7.523), ('BMW_Honda_Toyota_lift', 8.11), ('BMW_Honda_Nissan_lift', 9.134), ('BMW_Toyota_Audi_lift', 10.103), ('BMW_Honda_Acura_lift', 10.192), ('BMW_Nissan_Lexus_lift', 11.211), ('BMW_Toyota_Nissan_lift', 12.774), ('BMW_Nissan_Acura_lift', 13.67), ('BMW_Toyota_Lexus_lift', 14.46), ('BMW_Nissan_Audi_lift', 16.758), ('BMW_Lexus_Acura_lift', 36.468), ('BMW_Audi_Acura_lift', 48.246), ('BMW_Lexus_Audi_lift', 55.735)]\n",
      "\n",
      "\n",
      "[('Audi_Honda_BMW_lift', 8.756), ('Audi_Honda_Lexus_lift', 11.135), ('Audi_Toyota_BMW_lift', 13.859), ('Audi_Honda_Nissan_lift', 13.972), ('Audi_Nissan_BMW_lift', 14.171), ('Audi_Honda_Toyota_lift', 16.838), ('Audi_Toyota_Acura_lift', 16.936), ('Audi_Honda_Acura_lift', 17.552), ('Audi_Nissan_Lexus_lift', 18.08), ('Audi_Nissan_Acura_lift', 20.675), ('Audi_Toyota_Nissan_lift', 24.513), ('Audi_Toyota_Lexus_lift', 27.691), ('Audi_BMW_Acura_lift', 43.958), ('Audi_Lexus_BMW_lift', 59.568), ('Audi_Lexus_Acura_lift', 64.999)]\n",
      "\n",
      "\n",
      "[('Acura_Toyota_BMW_lift', 10.307), ('Acura_Honda_BMW_lift', 14.007), ('Acura_Toyota_Audi_lift', 15.464), ('Acura_Nissan_BMW_lift', 16.389), ('Acura_Honda_Toyota_lift', 16.877), ('Acura_Honda_Lexus_lift', 17.223), ('Acura_Nissan_Lexus_lift', 17.847), ('Acura_Honda_Nissan_lift', 18.619), ('Acura_Honda_Audi_lift', 18.658), ('Acura_Nissan_Audi_lift', 20.249), ('Acura_Toyota_Nissan_lift', 21.666), ('Acura_Toyota_Lexus_lift', 26.215), ('Acura_Lexus_BMW_lift', 55.138), ('Acura_Lexus_Audi_lift', 81.618), ('Acura_BMW_Audi_lift', 96.416)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tri_gram(makes):\n",
    "    for outer_make in makes:\n",
    "\n",
    "        frequency = {}   # count comentioned \n",
    "        lift = {}\n",
    "        temp = pd.read_csv('data/csv_data/{}.csv'.format(outer_make))\n",
    "        num_review['{}'.format(outer_make)] = temp.shape[0]\n",
    "        new_sort = []\n",
    "        \n",
    "        mid_makes = [make for make in makes if make != outer_make]\n",
    "        for mid_make in mid_makes:\n",
    "            for inner_make in [make for make in mid_makes if make != mid_make]:\n",
    "                combined_name = '{}_{}_{}'.format(outer_make, mid_make, inner_make)\n",
    "                counter = 0   # counter for appearence\n",
    "    \n",
    "                for review in temp['review']:\n",
    "                    if mid_make in str(review):\n",
    "                        if inner_make in str(review):\n",
    "                            counter += 1\n",
    "                frequency[combined_name] = counter\n",
    "                lift[combined_name+'_lift'] = round(frequency[combined_name] / \\\n",
    "                        (num_review[combined_name.split('_')[0]] * \\\n",
    "                        num_review[combined_name.split('_')[1]] * \\\n",
    "                        num_review[combined_name.split('_')[2]]) * (10**13), 3)   # scale by 10e13 and keep 3 digits\n",
    "                \n",
    "        sorted_lift = sorted(lift.items(), key=operator.itemgetter(1))          # sort dict by value\n",
    "#       the sorted dict will have some over lapping, like Honda_Nissan_Toyota and Honda_Toyota_Nissan, they have same score\n",
    "#       so, just need keep even index data.\n",
    "        for i in range(0, len(sorted_lift), 2):\n",
    "            new_sort.append(sorted_lift[i])\n",
    "        print(new_sort) \n",
    "        print('\\n')\n",
    "        \n",
    "tri_gram(makes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most significant bandary in these 7 brands is like the Figures showed above, Lexus car and General cars have a kind seperate social community. Members in top score of each brand is those more closer in the <a href=\"#Figure1\">Figure 1</a>. \n",
    "Also, hidden relations we mentioned is clearly displied, Honda and Toyota was co-mentioned with Lexus or Acura many times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_score_gen(makes):\n",
    "    for make in makes:\n",
    "        corpus = []\n",
    "        temp = pd.read_csv('data/csv_data/{}.csv'.format(make))\n",
    "        for review in temp['review']:\n",
    "            corpus.append(pre.string_processor(str(review)))\n",
    "        count_vect = CountVectorizer()\n",
    "        df_bow = pd.DataFrame(data=count_vect.fit_transform(raw_documents=corpus).toarray())\n",
    "        column_nums, terms = zip(*sorted(zip(count_vect.vocabulary_.values(), count_vect.vocabulary_.keys())))\n",
    "        df_bow.column_nums = terms\n",
    "                          \n",
    "        ldia = LDiA(n_components=10)\n",
    "        ldia.fit_transform(df_bow)\n",
    "                          \n",
    "        df_topics = pd.DataFrame(data=ldia.components_.T, index=terms)\n",
    "        df_topics.to_csv('data/topics/{}_topic.csv'.format(make))\n",
    "                          \n",
    "\n",
    "def topic_word_gen(makes):\n",
    "    for make in makes:\n",
    "        df = pd.read_csv('data/topics/{}_topic.csv'.format(make), index_col='Unnamed: 0')\n",
    "\n",
    "        df_words = pd.DataFrame()\n",
    "        for i in df.columns:\n",
    "            df_words['File{}'.format(i)] = list(df[i].nlargest(9).index)\n",
    "\n",
    "        df_words.to_csv('data/topics/{}_topic_word.csv'.format(make), index=False)\n",
    "    \n",
    "topic_score_gen(makes)\n",
    "topic_word_gen(makes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File0</th>\n",
       "      <th>File1</th>\n",
       "      <th>File2</th>\n",
       "      <th>File3</th>\n",
       "      <th>File4</th>\n",
       "      <th>File5</th>\n",
       "      <th>File6</th>\n",
       "      <th>File7</th>\n",
       "      <th>File8</th>\n",
       "      <th>File9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tire</td>\n",
       "      <td>bmw</td>\n",
       "      <td>car</td>\n",
       "      <td>look</td>\n",
       "      <td>nbsp</td>\n",
       "      <td>price</td>\n",
       "      <td>engine</td>\n",
       "      <td>car</td>\n",
       "      <td>drive</td>\n",
       "      <td>bmw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wheel</td>\n",
       "      <td>car</td>\n",
       "      <td>time</td>\n",
       "      <td>com</td>\n",
       "      <td>bmw</td>\n",
       "      <td>dealer</td>\n",
       "      <td>the</td>\n",
       "      <td>bmw</td>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>dealer</td>\n",
       "      <td>get</td>\n",
       "      <td>black</td>\n",
       "      <td>lease</td>\n",
       "      <td>lease</td>\n",
       "      <td>fuel</td>\n",
       "      <td>audi</td>\n",
       "      <td>speed</td>\n",
       "      <td>lexus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>winter</td>\n",
       "      <td>service</td>\n",
       "      <td>day</td>\n",
       "      <td>thank</td>\n",
       "      <td>car</td>\n",
       "      <td>deal</td>\n",
       "      <td>gas</td>\n",
       "      <td>new</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>package</td>\n",
       "      <td>mile</td>\n",
       "      <td>go</td>\n",
       "      <td>color</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>invoice</td>\n",
       "      <td>power</td>\n",
       "      <td>like</td>\n",
       "      <td>manual</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>snow</td>\n",
       "      <td>problem</td>\n",
       "      <td>drive</td>\n",
       "      <td>leather</td>\n",
       "      <td>host</td>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "      <td>year</td>\n",
       "      <td>awd</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>warranty</td>\n",
       "      <td>the</td>\n",
       "      <td>http</td>\n",
       "      <td>prices</td>\n",
       "      <td>msrp</td>\n",
       "      <td>torque</td>\n",
       "      <td>think</td>\n",
       "      <td>bmw</td>\n",
       "      <td>drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>the</td>\n",
       "      <td>week</td>\n",
       "      <td>www</td>\n",
       "      <td>forum</td>\n",
       "      <td>good</td>\n",
       "      <td>hp</td>\n",
       "      <td>good</td>\n",
       "      <td>like</td>\n",
       "      <td>acura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mile</td>\n",
       "      <td>oil</td>\n",
       "      <td>like</td>\n",
       "      <td>post</td>\n",
       "      <td>year</td>\n",
       "      <td>month</td>\n",
       "      <td>high</td>\n",
       "      <td>buy</td>\n",
       "      <td>road</td>\n",
       "      <td>infiniti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     File0     File1  File2    File3    File4    File5   File6  File7   File8  \\\n",
       "0     tire       bmw    car     look     nbsp    price  engine    car   drive   \n",
       "1    wheel       car   time      com      bmw   dealer     the    bmw     car   \n",
       "2    sport    dealer    get    black    lease    lease    fuel   audi   speed   \n",
       "3   winter   service    day    thank      car     deal     gas    new     the   \n",
       "4  package      mile     go    color  vehicle  invoice   power   like  manual   \n",
       "5     snow   problem  drive  leather     host      car     car   year     awd   \n",
       "6      the  warranty    the     http   prices     msrp  torque  think     bmw   \n",
       "7      car       the   week      www    forum     good      hp   good    like   \n",
       "8     mile       oil   like     post     year    month    high    buy    road   \n",
       "\n",
       "      File9  \n",
       "0       bmw  \n",
       "1       car  \n",
       "2     lexus  \n",
       "3       the  \n",
       "4      like  \n",
       "5      good  \n",
       "6     drive  \n",
       "7     acura  \n",
       "8  infiniti  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('data/topics/BMW_topic_word.csv')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def simple_processor(token):\n",
    "    str = unidecode(token)\n",
    "    str = strip_punctuation(str)\n",
    "    str = strip_multiple_whitespaces(str)\n",
    "\n",
    "    tokens = str.split(' ')\n",
    "    tokens = [ps.stem(token) for token in tokens]\n",
    "    str = ' '.join(tokens)\n",
    "    return str\n",
    "\n",
    "def re_pre(makes):\n",
    "    for make in makes:\n",
    "        df = pd.read_csv('data/csv_data/{}.csv'.format(make))\n",
    "\n",
    "        corpus = []\n",
    "        for review in df['review']:\n",
    "            corpus.append(simple_processor(str(review)))\n",
    "\n",
    "        with open('data/corpus/{}.txt'.format(make), mode='w', encoding='utf-8') as f:\n",
    "            for line in corpus:\n",
    "                f.write(line + '\\n')\n",
    "            \n",
    "re_pre(makes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = multiprocessing.cpu_count()    # num of processors\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in open(path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)\n",
    "            \n",
    "            \n",
    "path_list = ['data/corpus/{}.txt'.format(make) for make in makes]\n",
    "for path_ in path_list:\n",
    "    path = path_\n",
    "    sentence = MyCorpus()\n",
    "    model_w2v = gensim.models.Word2Vec(sentences=sentence,\n",
    "                                       workers=worker,\n",
    "                                      sg=0,\n",
    "                                      size=300)\n",
    "\n",
    "    model_name = '{}_W2V_model'.format(path.split('/')[-1].split('.')[0])\n",
    "    model_w2v.save('pretrained/{}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rs', 0.558880090713501),\n",
       " ('rodeo', 0.5536184310913086),\n",
       " ('fx', 0.548690676689148),\n",
       " ('kappa', 0.5430014133453369),\n",
       " ('nsx', 0.53934645652771),\n",
       " ('rl', 0.5325500965118408),\n",
       " ('murano', 0.5292455554008484),\n",
       " ('gs', 0.5244740843772888),\n",
       " ('cl', 0.521479606628418),\n",
       " ('citat', 0.5214464664459229),\n",
       " ('lexus', 0.5206010341644287),\n",
       " ('sh', 0.5205627679824829),\n",
       " ('rdx', 0.5198386907577515),\n",
       " ('antra', 0.5197892189025879),\n",
       " ('infin', 0.5187973976135254),\n",
       " ('nuvi', 0.511254072189331),\n",
       " ('futher', 0.5107113718986511),\n",
       " ('amg', 0.5091148018836975),\n",
       " ('avalon', 0.5088338851928711),\n",
       " ('soundgat', 0.5080039501190186)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "model_path = 'pretrained/Honda_W2V_model'\n",
    "model_w2v = gensim.models.Word2Vec.load(model_path)\n",
    "model_w2v.most_similar('{}'.format(ps.stem('Accura')), topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Word2Vect model, it goes deeply with the relations, not only just brands, certain models showed mostly. Like the in the Lift score of Acura, the most related brand is Audi, and RS is the high performance car of Audi, Murano is from Nissan, the absence of BMW and Lexus may caused by the mis-count on model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
